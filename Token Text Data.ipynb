{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization in NLP\n",
    "\n",
    "Tokenization is essentially splitting a phrase, sentence, paragraph,\n",
    "enire text documen into smaller units, each of these smaller units are called tokens\n",
    "\n",
    "\n",
    "#### Why is tokenization required in NLP ?\n",
    "\n",
    " Break and conquer\n",
    " This is important because the meaning of the text could ieasily be interpreted by analyzing the wrods present in the text\n",
    "\n",
    "\n",
    "- There are numerous uses of doing this .\n",
    "- We can use this tokenized form to:\n",
    "\n",
    "1. Count the number of words in the text\n",
    "2. COunt the frequency of the word, that is the number of times a particular word is present\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Different Methods to perform Tokenization in python\n",
    "\n",
    "1. Using split() Function\n",
    "2. Using Regular Expressions\n",
    "3. Using NLTK\n",
    "4. Using Spacy\n",
    "5. Using Keras\n",
    "6. Using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
    "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
    "liquid-fuel launch vehicle to orbit the Earth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars',\n",
       " ' In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization using split()\n",
    "token1 = text.split()\n",
    "token1_sentence = text.split('.')\n",
    "token1_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Token words: \n",
      " ['Founded', 'in', '2002', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 'In', '2008', 'SpaceX', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']\n",
      "\n",
      "Token sentences: \n",
      "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars', 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization using Regular Expressions\n",
    "\n",
    "import re\n",
    "\n",
    "# word tokenization\n",
    "token2 = re.findall(\"[\\w']+\", text)\n",
    "\n",
    "# sentence tokenization\n",
    "token2_sentence = re.compile(\"[.!?] \").split(text)\n",
    "print(f\" Token words: \\n {token2}\")\n",
    "print(f\"\\nToken sentences: \\n{token2_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(token1))\n",
    "print(type(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word Token :\n",
      "['Founded', 'in', '2002', ',', 'SpaceX', '’', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', '’', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']\n",
      "Sent Token :\n",
      "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars.', 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization using NLTK\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "token3 = word_tokenize(text)\n",
    "token3_sentence = sent_tokenize(text)\n",
    "\n",
    "print(' Word Token :', token3, sep='\\n')\n",
    "print('Sent Token :', token3_sentence, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOkenization using Spacy\n",
    "\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded',\n",
       " 'in',\n",
       " '2002',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’s',\n",
       " 'mission',\n",
       " 'is',\n",
       " 'to',\n",
       " 'enable',\n",
       " 'humans',\n",
       " 'to',\n",
       " 'become',\n",
       " 'a',\n",
       " 'spacefaring',\n",
       " 'civilization',\n",
       " 'and',\n",
       " 'a',\n",
       " 'multi',\n",
       " '-',\n",
       " 'planet',\n",
       " '\\n',\n",
       " 'species',\n",
       " 'by',\n",
       " 'building',\n",
       " 'a',\n",
       " 'self',\n",
       " '-',\n",
       " 'sustaining',\n",
       " 'city',\n",
       " 'on',\n",
       " 'Mars',\n",
       " '.',\n",
       " 'In',\n",
       " '2008',\n",
       " ',',\n",
       " 'SpaceX',\n",
       " '’s',\n",
       " 'Falcon',\n",
       " '1',\n",
       " 'became',\n",
       " 'the',\n",
       " 'first',\n",
       " 'privately',\n",
       " 'developed',\n",
       " '\\n',\n",
       " 'liquid',\n",
       " '-',\n",
       " 'fuel',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'to',\n",
       " 'orbit',\n",
       " 'the',\n",
       " 'Earth',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English()\n",
    "\n",
    "text1 = nlp(text)\n",
    "\n",
    "token4= []\n",
    "for token in text1:\n",
    "    token4.append(token.text)\n",
    "token4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \\nspecies by building a self-sustaining city on Mars.',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed \\nliquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "\n",
    "sent = nlp.create_pipe('sentencizer')\n",
    "nlp.add_pipe(sent)\n",
    "\n",
    "text2 = nlp(text)\n",
    "\n",
    "token4_sent = []\n",
    "\n",
    "for sent in text2.sents:\n",
    "    token4_sent.append(sent.text)\n",
    "token4_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization using Keras\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "token5 = text_to_word_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['founded', 'in', '2002', 'spacex’s', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'mars', 'in', '2008', 'spacex’s', 'falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'earth']\n"
     ]
    }
   ],
   "source": [
    "print(token5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Founded', 'in', 'SpaceX', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi', 'planet', 'species', 'by', 'building', 'a', 'self', 'sustaining', 'city', 'on', 'Mars', 'In', 'SpaceX', 's', 'Falcon', 'became', 'the', 'first', 'privately', 'developed', 'liquid', 'fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth']\n"
     ]
    }
   ],
   "source": [
    "token6 = list(tokenize(text))\n",
    "print(token6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet ',\n",
       " 'species by building a self-sustaining city on Mars.',\n",
       " 'In 2008, SpaceX’s Falcon 1 became the first privately developed ',\n",
       " 'liquid-fuel launch vehicle to orbit the Earth.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token6_sentence = split_sentences(text)\n",
    "token6_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
