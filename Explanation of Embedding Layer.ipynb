{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#data visualisation and manipulation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "#set matplotlib inline and displays graphs below the corressponding cell\n",
    "\n",
    "%matplotlib inline\n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# tensorflow keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = 'bitty bought a bit of butter'\n",
    "sample_2 = 'but the bit of butter was a bit bitter'\n",
    "sample_3 = 'so she bought some better butter to make the bitter butter better'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bitty bought a bit of butter', 'but the bit of butter was a bit bitter', 'so she bought some better butter to make the bitter butter better']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "corp = [sample_1, sample_2, sample_3]\n",
    "no_docs = len(corp)\n",
    "print(corp)\n",
    "print(no_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The encoding for document 1 is: [44, 31, 1, 45, 20, 33]\n",
      " The encoding for document 2 is: [47, 8, 45, 20, 33, 28, 1, 45, 49]\n",
      " The encoding for document 3 is: [12, 49, 31, 7, 24, 33, 3, 13, 8, 49, 33, 24]\n"
     ]
    }
   ],
   "source": [
    "# encoding\n",
    "vocab_size = 50\n",
    "encod_corp = []\n",
    "for i, doc in enumerate(corp):\n",
    "    encod_corp.append(one_hot(doc, 50))\n",
    "    print(f\" The encoding for document {i+1} is: {one_hot(doc, 50)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of words in any document is: 12\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "# Padding the doc\n",
    "# the keras embedding layer requires all individual documents to be the same length\n",
    "\n",
    "#length of maximum document, will be nedded whenever create embeddings for words\n",
    "\n",
    "maxlen = -1 \n",
    "for doc in corp:\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    if maxlen < len(tokens):\n",
    "        maxlen = len(tokens)\n",
    "print(f'The maximum number of words in any document is: {maxlen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No of padded documents: 3\n"
     ]
    }
   ],
   "source": [
    "# now to create embeddings all of our docs need to be of same length\n",
    "\n",
    "pad_corp = pad_sequences(encod_corp, maxlen=maxlen, padding='post',\n",
    "                         value=0.0)\n",
    "print(f\" No of padded documents: {len(pad_corp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 31,  1, 45, 20, 33,  0,  0,  0,  0,  0,  0],\n",
       "       [47,  8, 45, 20, 33, 28,  1, 45, 49,  0,  0,  0],\n",
       "       [12, 49, 31,  7, 24, 33,  3, 13,  8, 49, 33, 24]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [44 31  1 45 20 33  0  0  0  0  0  0]\n",
      "2 [47  8 45 20 33 28  1 45 49  0  0  0]\n",
      "3 [12 49 31  7 24 33  3 13  8 49 33 24]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(pad_corp):\n",
    "    print(i+1, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nshape of input \\neach document has 12 elenment or words which is the value of our maxlen variable\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Actually creating the embeddings using keras embedding layer\n",
    "# wwe will embed the words into vectors of 8 dimensions\n",
    "\n",
    "#Specifying the input shape\n",
    "\n",
    "input = Input(shape=(no_docs, maxlen),dtype='float64')\n",
    "\"\"\"\n",
    "shape of input \n",
    "each document has 12 elenment or words which is the value of our maxlen variable\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_input = Input(shape=(maxlen,), dtype='float64')\n",
    "\n",
    "#create the embedding\n",
    "\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=8, \n",
    "                           input_length=maxlen)(word_input)\n",
    "word_vec = Flatten()(word_embedding)\n",
    "embed_model = Model([word_input], word_vec)\n",
    "# combining all into a keras model\n",
    "\n",
    "# Parameters of the embedding layer: \n",
    "# input_dim = the vocab size that we will choose. the number of unique words in the vocab\n",
    "# out_dim = the number of dimensions we wish to embed into.\n",
    "# each word will be represented by a vector of this much dimensions\n",
    "\n",
    "# input_length = length of the maximum ducument. which is stored in maxlen variable in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding/Identity:0\", shape=(None, 12, 8), dtype=float32)\n",
      "Tensor(\"flatten/Identity:0\", shape=(None, 96), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(word_embedding)\n",
    "print(word_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model.compile(optimizer= tf.keras.optimizers.Adam(lr=1e-3), \n",
    "                    loss='binary_crossentropy', metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"embedding/Identity:0\", shape=(None, 12, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(word_embedding))\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 12, 8)             400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 96)                0         \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed_model.predict(pad_corp)\n",
    "#finally getting the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape of embeddings: (3, 96)\n",
      "[[-0.02321883  0.00590817 -0.03908654  0.00891554 -0.04585463 -0.03270767\n",
      "  -0.04084574  0.0353308  -0.01433499  0.04560712 -0.04818144 -0.00751668\n",
      "   0.03635092 -0.04925726 -0.01476747 -0.02798288 -0.0201286   0.03721992\n",
      "   0.00277926  0.00698855  0.01600209 -0.01949042  0.03407076  0.02152048\n",
      "   0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353 -0.04315567\n",
      "   0.00123763 -0.04305519 -0.0088929  -0.02109972 -0.02930001 -0.00044409\n",
      "   0.01457237  0.01910624  0.02606511 -0.01090483  0.03869852  0.04664112\n",
      "   0.04851368  0.04248032  0.04791268  0.01435616 -0.0347581   0.00446444\n",
      "  -0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "   0.01970177  0.04845733 -0.02522277  0.01396323  0.02518037 -0.00034447\n",
      "  -0.04707885 -0.03438509  0.01970177  0.04845733 -0.02522277  0.01396323\n",
      "   0.02518037 -0.00034447 -0.04707885 -0.03438509  0.01970177  0.04845733\n",
      "  -0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "   0.01970177  0.04845733 -0.02522277  0.01396323  0.02518037 -0.00034447\n",
      "  -0.04707885 -0.03438509  0.01970177  0.04845733 -0.02522277  0.01396323\n",
      "   0.02518037 -0.00034447 -0.04707885 -0.03438509  0.01970177  0.04845733]\n",
      " [-0.04227995  0.01401833 -0.03013716  0.01399149  0.02087561  0.0112612\n",
      "  -0.0314934  -0.00700165 -0.04621081  0.02770181  0.0025723   0.04165497\n",
      "   0.02686701  0.02132541  0.00695109 -0.00077728  0.00773871 -0.01210929\n",
      "   0.04502001  0.03467814  0.01702353 -0.04315567  0.00123763 -0.04305519\n",
      "  -0.0088929  -0.02109972 -0.02930001 -0.00044409  0.01457237  0.01910624\n",
      "   0.02606511 -0.01090483  0.03869852  0.04664112  0.04851368  0.04248032\n",
      "   0.04791268  0.01435616 -0.0347581   0.00446444  0.01070918  0.0305489\n",
      "  -0.02941436  0.01230022 -0.03439088  0.01364226 -0.01469926 -0.03222756\n",
      "  -0.0201286   0.03721992  0.00277926  0.00698855  0.01600209 -0.01949042\n",
      "   0.03407076  0.02152048  0.00773871 -0.01210929  0.04502001  0.03467814\n",
      "   0.01702353 -0.04315567  0.00123763 -0.04305519 -0.01306868 -0.02709041\n",
      "  -0.0242114  -0.02563035  0.00901183 -0.01553575  0.00896185 -0.00925766\n",
      "  -0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "   0.01970177  0.04845733 -0.02522277  0.01396323  0.02518037 -0.00034447\n",
      "  -0.04707885 -0.03438509  0.01970177  0.04845733 -0.02522277  0.01396323\n",
      "   0.02518037 -0.00034447 -0.04707885 -0.03438509  0.01970177  0.04845733]\n",
      " [ 0.02329187 -0.01123763 -0.0137086   0.03749334  0.02482288  0.00270748\n",
      "  -0.03641634  0.04173858 -0.01306868 -0.02709041 -0.0242114  -0.02563035\n",
      "   0.00901183 -0.01553575  0.00896185 -0.00925766 -0.01433499  0.04560712\n",
      "  -0.04818144 -0.00751668  0.03635092 -0.04925726 -0.01476747 -0.02798288\n",
      "   0.04738671  0.01472083  0.02616413 -0.04863381 -0.00579066  0.00367569\n",
      "  -0.00320357  0.00459759  0.01106555 -0.01144284 -0.04359411  0.014317\n",
      "   0.02111134 -0.00415372  0.0463086   0.00376934  0.03869852  0.04664112\n",
      "   0.04851368  0.04248032  0.04791268  0.01435616 -0.0347581   0.00446444\n",
      "  -0.02409266 -0.04672574 -0.03265252  0.03787248 -0.0342767  -0.03434525\n",
      "   0.04999221  0.00570459  0.02245637 -0.03129915  0.04432792 -0.04056281\n",
      "  -0.00093592 -0.0150178  -0.00992023 -0.04209812 -0.04621081  0.02770181\n",
      "   0.0025723   0.04165497  0.02686701  0.02132541  0.00695109 -0.00077728\n",
      "  -0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183 -0.01553575\n",
      "   0.00896185 -0.00925766  0.03869852  0.04664112  0.04851368  0.04248032\n",
      "   0.04791268  0.01435616 -0.0347581   0.00446444  0.01106555 -0.01144284\n",
      "  -0.04359411  0.014317    0.02111134 -0.00415372  0.0463086   0.00376934]]\n"
     ]
    }
   ],
   "source": [
    "print(f\" shape of embeddings: {embeddings.shape}\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of embeddings: (3, 12, 8)\n",
      "[[[-0.02321883  0.00590817 -0.03908654  0.00891554 -0.04585463\n",
      "   -0.03270767 -0.04084574  0.0353308 ]\n",
      "  [-0.01433499  0.04560712 -0.04818144 -0.00751668  0.03635092\n",
      "   -0.04925726 -0.01476747 -0.02798288]\n",
      "  [-0.0201286   0.03721992  0.00277926  0.00698855  0.01600209\n",
      "   -0.01949042  0.03407076  0.02152048]\n",
      "  [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353\n",
      "   -0.04315567  0.00123763 -0.04305519]\n",
      "  [-0.0088929  -0.02109972 -0.02930001 -0.00044409  0.01457237\n",
      "    0.01910624  0.02606511 -0.01090483]\n",
      "  [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268\n",
      "    0.01435616 -0.0347581   0.00446444]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]]\n",
      "\n",
      " [[-0.04227995  0.01401833 -0.03013716  0.01399149  0.02087561\n",
      "    0.0112612  -0.0314934  -0.00700165]\n",
      "  [-0.04621081  0.02770181  0.0025723   0.04165497  0.02686701\n",
      "    0.02132541  0.00695109 -0.00077728]\n",
      "  [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353\n",
      "   -0.04315567  0.00123763 -0.04305519]\n",
      "  [-0.0088929  -0.02109972 -0.02930001 -0.00044409  0.01457237\n",
      "    0.01910624  0.02606511 -0.01090483]\n",
      "  [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268\n",
      "    0.01435616 -0.0347581   0.00446444]\n",
      "  [ 0.01070918  0.0305489  -0.02941436  0.01230022 -0.03439088\n",
      "    0.01364226 -0.01469926 -0.03222756]\n",
      "  [-0.0201286   0.03721992  0.00277926  0.00698855  0.01600209\n",
      "   -0.01949042  0.03407076  0.02152048]\n",
      "  [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353\n",
      "   -0.04315567  0.00123763 -0.04305519]\n",
      "  [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183\n",
      "   -0.01553575  0.00896185 -0.00925766]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]\n",
      "  [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885\n",
      "   -0.03438509  0.01970177  0.04845733]]\n",
      "\n",
      " [[ 0.02329187 -0.01123763 -0.0137086   0.03749334  0.02482288\n",
      "    0.00270748 -0.03641634  0.04173858]\n",
      "  [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183\n",
      "   -0.01553575  0.00896185 -0.00925766]\n",
      "  [-0.01433499  0.04560712 -0.04818144 -0.00751668  0.03635092\n",
      "   -0.04925726 -0.01476747 -0.02798288]\n",
      "  [ 0.04738671  0.01472083  0.02616413 -0.04863381 -0.00579066\n",
      "    0.00367569 -0.00320357  0.00459759]\n",
      "  [ 0.01106555 -0.01144284 -0.04359411  0.014317    0.02111134\n",
      "   -0.00415372  0.0463086   0.00376934]\n",
      "  [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268\n",
      "    0.01435616 -0.0347581   0.00446444]\n",
      "  [-0.02409266 -0.04672574 -0.03265252  0.03787248 -0.0342767\n",
      "   -0.03434525  0.04999221  0.00570459]\n",
      "  [ 0.02245637 -0.03129915  0.04432792 -0.04056281 -0.00093592\n",
      "   -0.0150178  -0.00992023 -0.04209812]\n",
      "  [-0.04621081  0.02770181  0.0025723   0.04165497  0.02686701\n",
      "    0.02132541  0.00695109 -0.00077728]\n",
      "  [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183\n",
      "   -0.01553575  0.00896185 -0.00925766]\n",
      "  [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268\n",
      "    0.01435616 -0.0347581   0.00446444]\n",
      "  [ 0.01106555 -0.01144284 -0.04359411  0.014317    0.02111134\n",
      "   -0.00415372  0.0463086   0.00376934]]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = embeddings.reshape(-1, maxlen, 8)\n",
    "print(f\"shape of embeddings: {embeddings.shape}\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The encoding for 1 th word in 1 document is: \n",
      "\n",
      " [-0.02321883  0.00590817 -0.03908654  0.00891554 -0.04585463 -0.03270767\n",
      " -0.04084574  0.0353308 ]\n",
      " The encoding for 2 th word in 1 document is: \n",
      "\n",
      " [-0.01433499  0.04560712 -0.04818144 -0.00751668  0.03635092 -0.04925726\n",
      " -0.01476747 -0.02798288]\n",
      " The encoding for 3 th word in 1 document is: \n",
      "\n",
      " [-0.0201286   0.03721992  0.00277926  0.00698855  0.01600209 -0.01949042\n",
      "  0.03407076  0.02152048]\n",
      " The encoding for 4 th word in 1 document is: \n",
      "\n",
      " [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353 -0.04315567\n",
      "  0.00123763 -0.04305519]\n",
      " The encoding for 5 th word in 1 document is: \n",
      "\n",
      " [-0.0088929  -0.02109972 -0.02930001 -0.00044409  0.01457237  0.01910624\n",
      "  0.02606511 -0.01090483]\n",
      " The encoding for 6 th word in 1 document is: \n",
      "\n",
      " [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268  0.01435616\n",
      " -0.0347581   0.00446444]\n",
      " The encoding for 7 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 8 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 9 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 10 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 11 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 12 th word in 1 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 1 th word in 2 document is: \n",
      "\n",
      " [-0.04227995  0.01401833 -0.03013716  0.01399149  0.02087561  0.0112612\n",
      " -0.0314934  -0.00700165]\n",
      " The encoding for 2 th word in 2 document is: \n",
      "\n",
      " [-0.04621081  0.02770181  0.0025723   0.04165497  0.02686701  0.02132541\n",
      "  0.00695109 -0.00077728]\n",
      " The encoding for 3 th word in 2 document is: \n",
      "\n",
      " [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353 -0.04315567\n",
      "  0.00123763 -0.04305519]\n",
      " The encoding for 4 th word in 2 document is: \n",
      "\n",
      " [-0.0088929  -0.02109972 -0.02930001 -0.00044409  0.01457237  0.01910624\n",
      "  0.02606511 -0.01090483]\n",
      " The encoding for 5 th word in 2 document is: \n",
      "\n",
      " [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268  0.01435616\n",
      " -0.0347581   0.00446444]\n",
      " The encoding for 6 th word in 2 document is: \n",
      "\n",
      " [ 0.01070918  0.0305489  -0.02941436  0.01230022 -0.03439088  0.01364226\n",
      " -0.01469926 -0.03222756]\n",
      " The encoding for 7 th word in 2 document is: \n",
      "\n",
      " [-0.0201286   0.03721992  0.00277926  0.00698855  0.01600209 -0.01949042\n",
      "  0.03407076  0.02152048]\n",
      " The encoding for 8 th word in 2 document is: \n",
      "\n",
      " [ 0.00773871 -0.01210929  0.04502001  0.03467814  0.01702353 -0.04315567\n",
      "  0.00123763 -0.04305519]\n",
      " The encoding for 9 th word in 2 document is: \n",
      "\n",
      " [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183 -0.01553575\n",
      "  0.00896185 -0.00925766]\n",
      " The encoding for 10 th word in 2 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 11 th word in 2 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 12 th word in 2 document is: \n",
      "\n",
      " [-0.02522277  0.01396323  0.02518037 -0.00034447 -0.04707885 -0.03438509\n",
      "  0.01970177  0.04845733]\n",
      " The encoding for 1 th word in 3 document is: \n",
      "\n",
      " [ 0.02329187 -0.01123763 -0.0137086   0.03749334  0.02482288  0.00270748\n",
      " -0.03641634  0.04173858]\n",
      " The encoding for 2 th word in 3 document is: \n",
      "\n",
      " [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183 -0.01553575\n",
      "  0.00896185 -0.00925766]\n",
      " The encoding for 3 th word in 3 document is: \n",
      "\n",
      " [-0.01433499  0.04560712 -0.04818144 -0.00751668  0.03635092 -0.04925726\n",
      " -0.01476747 -0.02798288]\n",
      " The encoding for 4 th word in 3 document is: \n",
      "\n",
      " [ 0.04738671  0.01472083  0.02616413 -0.04863381 -0.00579066  0.00367569\n",
      " -0.00320357  0.00459759]\n",
      " The encoding for 5 th word in 3 document is: \n",
      "\n",
      " [ 0.01106555 -0.01144284 -0.04359411  0.014317    0.02111134 -0.00415372\n",
      "  0.0463086   0.00376934]\n",
      " The encoding for 6 th word in 3 document is: \n",
      "\n",
      " [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268  0.01435616\n",
      " -0.0347581   0.00446444]\n",
      " The encoding for 7 th word in 3 document is: \n",
      "\n",
      " [-0.02409266 -0.04672574 -0.03265252  0.03787248 -0.0342767  -0.03434525\n",
      "  0.04999221  0.00570459]\n",
      " The encoding for 8 th word in 3 document is: \n",
      "\n",
      " [ 0.02245637 -0.03129915  0.04432792 -0.04056281 -0.00093592 -0.0150178\n",
      " -0.00992023 -0.04209812]\n",
      " The encoding for 9 th word in 3 document is: \n",
      "\n",
      " [-0.04621081  0.02770181  0.0025723   0.04165497  0.02686701  0.02132541\n",
      "  0.00695109 -0.00077728]\n",
      " The encoding for 10 th word in 3 document is: \n",
      "\n",
      " [-0.01306868 -0.02709041 -0.0242114  -0.02563035  0.00901183 -0.01553575\n",
      "  0.00896185 -0.00925766]\n",
      " The encoding for 11 th word in 3 document is: \n",
      "\n",
      " [ 0.03869852  0.04664112  0.04851368  0.04248032  0.04791268  0.01435616\n",
      " -0.0347581   0.00446444]\n",
      " The encoding for 12 th word in 3 document is: \n",
      "\n",
      " [ 0.01106555 -0.01144284 -0.04359411  0.014317    0.02111134 -0.00415372\n",
      "  0.0463086   0.00376934]\n"
     ]
    }
   ],
   "source": [
    "# 3 - 3 document\n",
    "# 12 - each document is made of 12 words which was our maximun length of any document\n",
    "# 8 - each word is 8 dimensional\n",
    "\n",
    "\n",
    "# getting encoding for a particular word in a specific document \n",
    "\n",
    "for i, doc in enumerate(embeddings):\n",
    "    for j, word in enumerate(doc):\n",
    "        print(f\" The encoding for {j+1} th word in {i+1} document is: \\n\\n {word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
